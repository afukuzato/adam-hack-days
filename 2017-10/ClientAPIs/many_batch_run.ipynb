{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook shows how to run a whole lot of propagations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adam import Batch\n",
    "from adam import PropagationParams\n",
    "from adam import OpmParams\n",
    "from adam import BatchRunManager\n",
    "from adam import Service\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets up a Service which uses the given token and URL to provide authorized access through the server through several wrapped modules. It also creates a project for you to work in that will be used for the rest of the notebook. Be sure to run service.teardown() when finished. \n",
    "\n",
    "If you don't have a token, see auth_demo to get one.\n",
    "\n",
    "Normally instead of 'ffffffff-ffff-ffff-ffff-ffffffffffff' you would use your team workspace project that was made for you by the ADAM team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://pro-equinox-162418.appspot.com/_ah/api/adam/v1\"\n",
    " # Reads your token from a file in current directory. For instructions on getting a token, see auth_demo notebook.\n",
    "token = open(os.getcwd() + '/token.txt').read()\n",
    "service = Service()\n",
    "service.setup(url, token, 'ffffffff-ffff-ffff-ffff-ffffffffffff')\n",
    "working_project = service.get_working_project()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates a propagation object. For now, it just creates a dummy object with slight variations to avoid creating duplicate objects. For detailed information on Batch creation, see test_single_batch_run notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(i):\n",
    "    state_vec = [130347560.13690618,\n",
    "                 -74407287.6018632,\n",
    "                 -35247598.541470632,\n",
    "                 23.935241263310683,\n",
    "                 27.146279819258538,\n",
    "                 10.346605942591514]\n",
    "    \n",
    "    start_time = datetime.datetime(2018, 2, 21, 0, 0, 0, 123456 + i)\n",
    "    end_time = datetime.datetime(2028, 2, 21, 0, 0, 0, 123456 + i)  # Ten years later.\n",
    "    \n",
    "    return Batch(PropagationParams({\n",
    "        'start_time': start_time.isoformat() + 'Z',\n",
    "        'end_time': end_time.isoformat() + 'Z',\n",
    "        'project_uuid': working_project.get_uuid(),\n",
    "    }), OpmParams({\n",
    "        'epoch': start_time.isoformat() + 'Z',\n",
    "        'state_vector': state_vec,\n",
    "        'mass': 500 + i,  # Create a small variation between batches.\n",
    "    }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a large number of batch runs and propagates them. This'll probably take ~10 minutes. It'll be faster to run the second time because the server is already all scaled up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 1000\n",
    "batches = [get_batch(i) for i in range(num_batches)]\n",
    "\n",
    "batch_run_manager = BatchRunManager(service.get_batches_module(), batches)\n",
    "batch_run_manager.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO(laura): This is actually not true because python notebooks do not run cells simultaneously. There are ways to make this work. Do it.\n",
    "\n",
    "To view the status of your runs while they're propagating, run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = batch_run_manager.get_latest_statuses()\n",
    "status_counts = [[s, len(status[s])] for s in status]\n",
    "print(tabulate.tabulate(status_counts, headers=\"\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the batches are all done propagating, you can view their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in batches:\n",
    "    if batch.get_calc_state() == 'FAILED':\n",
    "        error = 'unknown error'\n",
    "        if batch.get_results() is not None and batch.get_results().get_parts()[0] is not None:\n",
    "            error = batch.get_results().get_parts()[0].get_error()\n",
    "        print('Batch %s failed: %s' % (batch.get_uuid(), error))\n",
    "    else:\n",
    "        final_state_vector = batch.get_results().get_end_state_vector()\n",
    "        print('Batch %s ended at %s' % (batch.get_uuid(), final_state_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Please clean up by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.teardown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
